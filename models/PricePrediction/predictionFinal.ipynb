{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Mahine Learning Tools\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import  mean_squared_error \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Data Manipulation Tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization Tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Preprocessing Tools\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Dataset\n",
    "priceData = pd.read_csv(\"./data/processed/pricesList.csv\")\n",
    "rainfallData = pd.read_csv(\"./data/processed/rainfallData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index to the date\n",
    "def extractDate(data):\n",
    "    data2 = data.copy()\n",
    "    data2[\"Datetime\"] = pd.to_datetime(data2[['Year', 'Month']].assign(day=(data2[\"Week\"]-1)*7 +1))\n",
    "    data2 = data2.set_index('Datetime')\n",
    "    return data2\n",
    "priceData = extractDate(priceData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the unique values of the Name column in the dataset and iterate through them to display the price trend\n",
    "uniqueNames = priceData['Name'].unique()\n",
    "# fig with subplots for each name\n",
    "fig, axs = plt.subplots(len(uniqueNames), 1, figsize=(20, 15))\n",
    "for i, name in enumerate(uniqueNames):\n",
    "    # filter the dataset to get the data for the current name\n",
    "    priceData[priceData['Name'] == name][\"Price\"].plot(ax=axs[i], label=name)\n",
    "    axs[i].legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one of the crops\n",
    "plt.figure(figsize=(15, 7))\n",
    "priceData[priceData['Name'] == uniqueNames[0]][\"Price\"].loc[\"2020-01-01\":\"2023-12-15\"].copy().dropna().plot()\n",
    "plt.title(uniqueNames[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fig with one plot for all names\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 15))\n",
    "for i, name in enumerate(uniqueNames):\n",
    "    # filter the dataset to get the data for the current name from date 2016-01-01 to 2019-12-31\n",
    "    priceData[priceData['Name'] == name][\"Price\"].loc['2021-01-01':'2024-12-31'].plot(ax=ax, label=name)\n",
    "    ax.legend(loc='upper left')\n",
    "plt.title(\"Abnormal Price Trend in 2023 to 2024\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataset for processing\n",
    "df = priceData.copy()\n",
    "# extract only one vegetable for the prediction\n",
    "vegetable = uniqueNames[0]\n",
    "df = df[df[\"Name\"] == vegetable]\n",
    "df.drop(columns=[\"Name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the rainfall data with the price data\n",
    "for index, row in rainfallData.iterrows():\n",
    "    year = row['year']\n",
    "    month = row['month']\n",
    "    df.loc[(df['Year'] == year) & (df['Month'] == month), 'anuradhapura'] = row['anuradhapura']\n",
    "    df.loc[(df['Year'] == year) & (df['Month'] == month), 'jaffna'] = row['jaffna']\n",
    "    df.loc[(df['Year'] == year) & (df['Month'] == month), 'nuwaraeliya'] = row['nuwaraeliya']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Imputer for missing values in the dataset\n",
    "def imputeData(data, column):\n",
    "    imputer = SimpleImputer(missing_values = pd.NA, strategy ='mean')\n",
    "    imputer.fit(data[[column]])\n",
    "    # round to 2 decimal places\n",
    "    data[column] = imputer.transform(data[[column]])\n",
    "    data[column] = data[column].round(2)\n",
    "\n",
    "imputeData(df, \"Price\")\n",
    "imputeData(df, \"anuradhapura\")\n",
    "imputeData(df, \"jaffna\")\n",
    "imputeData(df, \"nuwaraeliya\")\n",
    "\n",
    "# drop the columns where price is null\n",
    "df = df.dropna(subset=[\"Price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLagFeatures(data, lag):\n",
    "    data2 = data.copy()\n",
    "    data2[\"Price_Lag\"] = data2[\"Price\"].shift(lag)\n",
    "    data2[\"anuradhapura_Lag\"] = data2[\"anuradhapura\"].shift(lag)\n",
    "    data2[\"jaffna_Lag\"] = data2[\"jaffna\"].shift(lag)\n",
    "    data2[\"nuwaraeliya_Lag\"] = data2[\"nuwaraeliya\"].shift(lag)\n",
    "    return data2\n",
    "df = createLagFeatures(df, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRollingFeatures(data, window):\n",
    "    data2 = data.copy()\n",
    "    data2[\"Price_Mean\"] = data2[\"Price\"].rolling(window=window).mean().shift(1)\n",
    "    data2[\"anuradhapura_Mean\"] = data2[\"anuradhapura\"].rolling(window=window).mean().shift(1)\n",
    "    data2[\"jaffna_Mean\"] = data2[\"jaffna\"].rolling(window=window).mean().shift(1)\n",
    "    data2[\"nuwaraeliya_Mean\"] = data2[\"nuwaraeliya\"].rolling(window=window).mean().shift(1)\n",
    "    return data2\n",
    "df = createRollingFeatures(df, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "df[\"Price\"].plot(ax=ax, label=\"After Imputation\", color=\"blue\")\n",
    "priceData[priceData[\"Name\"] == vegetable][\"Price\"].plot(ax=ax, label=\"Before Imputation\", color=\"red\")\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 9))\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', ax=ax)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = \"2022-08-01\"\n",
    "train = df.loc[df.index <= split_date]\n",
    "test = df.loc[df.index > split_date]\n",
    "fix, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "train['Price'].plot(ax=ax, label=\"Train Set\")\n",
    "test['Price'].plot(ax=ax, label=\"Test Set\")\n",
    "ax.axvline(split_date, color=\"black\", ls=\"--\")\n",
    "ax.legend(\"Training set\", \"Test Set\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the dataset into features and target\n",
    "FEATURES = [\"Week\", \"Month\", \"Year\",\n",
    "            #\"anuradhapura\", \"jaffna\", \"nuwaraeliya\", \n",
    "            \"Price_Lag\", # \"anuradhapura_Lag\", \"jaffna_Lag\", \"nuwaraeliya_Lag\",\n",
    "            \"Price_Mean\", # \"anuradhapura_Mean\", \"jaffna_Mean\", \"nuwaraeliya_Mean\"\n",
    "        ]\n",
    "TARGET = \"Price\"\n",
    "\n",
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fb_prophet = Prophet()\n",
    "fb_prophet.fit(train.reset_index().rename(columns={\"Datetime\": \"ds\", \"Price\": \"y\"}))\n",
    "\n",
    "# Evaluate the model\n",
    "prophet_pred = fb_prophet.predict(test.reset_index().rename(columns={\"Datetime\": \"ds\", \"Price\": \"y\"}))\n",
    "fix, ax = plt.subplots(figsize=(10, 5))\n",
    "fig = fb_prophet.plot(prophet_pred, ax=ax)\n",
    "test[\"Price\"].plot(ax=ax, label=\"True Price\", color=\"r\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "XGB_reg = XGBRegressor(n_estimators=2000, learning_rate=0.01)\n",
    "XGB_reg.fit(X_train, y_train, early_stopping_rounds=2000, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "# Evaluate the model\n",
    "XGB_pred = XGB_reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, XGB_pred)\n",
    "score = XGB_reg.score(X_test, y_test)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"Score: \", score*100)\n",
    "\n",
    "fix, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "y_test.plot(ax=ax, label=\"Actual Price\", color=\"red\")\n",
    "pd.Series(XGB_pred, index=y_test.index).plot(ax=ax, label=\"Predicted Price\", color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_reg = RandomForestRegressor(bootstrap=True, criterion='absolute_error',n_estimators=5000, random_state=None, verbose=False)\n",
    "RF_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "RF_pred = RF_reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, RF_pred)\n",
    "score = RF_reg.score(X_test, y_test)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"Score: \", score*100)\n",
    "\n",
    "fix, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "y_test.plot(ax=ax, label=\"Actual Price\", color=\"red\")\n",
    "pd.Series(RF_pred, index=y_test.index).plot(ax=ax, label=\"Predicted Price\", color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB_reg =  CatBoostRegressor(iterations=100000, depth=1, learning_rate=0.001, loss_function='RMSE')\n",
    "CB_reg.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
    "\n",
    "# Evaluate the model\n",
    "CB_pred = CB_reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, CB_pred)\n",
    "score = CB_reg.score(X_test, y_test)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"Score: \", score*100)\n",
    "\n",
    "fix, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "y_test.plot(ax=ax, label=\"Actual Price\", color=\"red\")\n",
    "pd.Series(CB_pred, index=y_test.index).plot(ax=ax, label=\"Predicted Price\", color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best model\n",
    "stepwise_fit = auto_arima(df[\"Price\"], exogenous=train, seasonal=True, m=12, stepwise=True, error_action=\"ignore\",max_p=3, max_q=3, max_P=3, max_Q=3,)\n",
    "# Train the model\n",
    "arima = SARIMAX(train[TARGET],exog=train[FEATURES], order=(stepwise_fit.get_params()[\"order\"]),seasonal_order=(0, 0, 0, 0))\n",
    "arima = arima.fit(maxiter=500, disp=False)\n",
    "# Evaluate the model\n",
    "start = len(train)\n",
    "end = len(train) + len(test) - 1\n",
    "arima_pred = arima.predict(start=start, end=end, typ=\"levels\", exog=test[FEATURES]).rename(\"ARIMA Predictions\")\n",
    "arima_pred.index = test.index\n",
    "fix, ax = plt.subplots(figsize=(10, 5))\n",
    "test[\"Price\"].plot(ax=ax, label=\"True Price\", color=\"red\")\n",
    "arima_pred.plot(ax=ax, label=\"ARIMA Predictions\", color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foreacast the price\n",
    "prediction = test.copy()\n",
    "prediction[\"XGB\"] = XGB_pred\n",
    "prediction[\"RF\"] = RF_pred\n",
    "prediction[\"CB\"] = CB_pred\n",
    "prediction[\"Prophet\"] = prophet_pred[\"yhat\"].values\n",
    "prediction[\"ARIMA\"] = arima_pred\n",
    "ax = prediction[\"Price\"].plot(label=\"Actual Price\", figsize=(15, 5), color=\"red\")\n",
    "prediction[\"XGB\"].plot(ax=ax, label=\"XG Boost\", style=\"--\", color=\"purple\")\n",
    "prediction[\"RF\"].plot(ax=ax, label=\"Random Forest\", style=\"--\", color=\"blue\")\n",
    "prediction[\"CB\"].plot(ax=ax, label=\"Cat Boost\", style=\"--\", color=\"cyan\")\n",
    "prediction[\"ARIMA\"].plot(ax=ax, label=\"ARIMA\", style=\"--\", color=\"orange\")\n",
    "prediction[\"Prophet\"].plot(ax=ax, label=\"Prophet\", style=\"--\", color=\"green\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Cross Validation\n",
    "splits = 2\n",
    "tss = TimeSeriesSplit(n_splits=splits, test_size=5,gap=-1)\n",
    "df2 = df.copy().sort_index()\n",
    "fig, axs = plt.subplots(splits, 1, figsize=(15, 15))\n",
    "fold = 0\n",
    "\n",
    "XGB_mse, RF_mse, CB_mse, ARIMA_mse = [], [], [], []\n",
    "XGB_rmse, RF_rmse, CB_rmse, ARIMA_rmse = [], [], [], []\n",
    "\n",
    "for train_idx, test_idx in tss.split(df2):\n",
    "    print(\"Prediction set \" + str(fold+1) + \" started\")\n",
    "    train_tss = df2.iloc[train_idx]\n",
    "    test_tss = df2.iloc[test_idx]\n",
    "    X_tss_train = train_tss[FEATURES]\n",
    "    y_tss_train = train_tss[TARGET]\n",
    "    X_tss_test = test_tss[FEATURES]\n",
    "    y_tss_test = test_tss[TARGET]\n",
    "    # plot train and test set\n",
    "    train_tss[\"Price\"].loc[\"2023-01-01\":].plot(ax=axs[fold], label=\"Train Set\", color=\"blue\")\n",
    "    test_tss[\"Price\"].plot(ax=axs[fold], label=\"Test Set\", color=\"red\")\n",
    "\n",
    "    # Train the models\n",
    "    XGB_reg = XGB_reg.fit(X_tss_train, y_tss_train)\n",
    "    RF_reg = RF_reg.fit(X_tss_train, y_tss_train)\n",
    "    CB_reg = CB_reg.fit(X_tss_train, y_tss_train)\n",
    "    arima = SARIMAX(train_tss[TARGET],exog=train_tss[FEATURES], order=(stepwise_fit.get_params()[\"order\"]),seasonal_order=(0, 0, 0, 0))\n",
    "    arima = arima.fit(maxiter=500, disp=False)\n",
    "\n",
    "    # Evaluate the models\n",
    "    XGB_pred = XGB_reg.predict(X_tss_test)\n",
    "    RF_pred = RF_reg.predict(X_tss_test)\n",
    "    CB_pred = CB_reg.predict(X_tss_test)\n",
    "    arima_pred = arima.predict(start=len(train_tss), end=len(train_tss) + len(test_tss) - 1, typ=\"levels\", exog=test_tss[FEATURES]).rename(\"ARIMA Predictions\")\n",
    "    arima_pred.index = test_tss.index\n",
    "\n",
    "    # plot the predictions\n",
    "    pd.Series(XGB_pred, index=y_tss_test.index).plot(ax=axs[fold], label=\"XG Boost\", color=\"green\", style=\"--\")\n",
    "    pd.Series(RF_pred, index=y_tss_test.index).plot(ax=axs[fold], label=\"Random Forest\", color=\"blue\", style=\"--\")\n",
    "    pd.Series(CB_pred, index=y_tss_test.index).plot(ax=axs[fold], label=\"Cat Boost\", color=\"orange\", style=\"--\")\n",
    "    arima_pred.plot(ax=axs[fold], label=\"ARIMA\", color=\"cyan\", style=\"--\")\n",
    "    axs[fold].legend(loc='upper left')\n",
    "\n",
    "    XGB_mse.append(mean_squared_error(y_tss_test, XGB_pred))\n",
    "    RF_mse.append(mean_squared_error(y_tss_test, RF_pred))\n",
    "    CB_mse.append(mean_squared_error(y_tss_test, CB_pred))\n",
    "    ARIMA_mse.append(mean_squared_error(y_tss_test, arima_pred))\n",
    "\n",
    "    # RMSE\n",
    "    XGB_rmse.append(np.sqrt(mean_squared_error(y_tss_test, XGB_pred)))\n",
    "    RF_rmse.append(np.sqrt(mean_squared_error(y_tss_test, RF_pred)))\n",
    "    CB_rmse.append(np.sqrt(mean_squared_error(y_tss_test, CB_pred)))\n",
    "    ARIMA_rmse.append(np.sqrt(mean_squared_error(y_tss_test, arima_pred)))\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "print(\"RMSE Values: \")\n",
    "\n",
    "print(\"XG Boost: \", np.mean(XGB_rmse))\n",
    "print(\"Random Forest: \", np.mean(RF_rmse))\n",
    "print(\"Cat Boost: \", np.mean(CB_rmse))\n",
    "print(\"ARIMA: \", np.mean(ARIMA_rmse))\n",
    "\n",
    "print(\"MSE Values: \")\n",
    "print(\"XG Boost: \", np.mean(XGB_mse))\n",
    "print(\"Random Forest: \", np.mean(RF_mse))\n",
    "print(\"Cat Boost: \", np.mean(CB_mse))\n",
    "print(\"ARIMA: \", np.mean(ARIMA_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "import pickle\n",
    "filename = './models/finalized_model.sav'\n",
    "\n",
    "# train the catboost model on the entire dataset\n",
    "CB_reg = CB_reg.fit(df[FEATURES], df[TARGET])\n",
    "\n",
    "pickle.dump(CB_reg, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
