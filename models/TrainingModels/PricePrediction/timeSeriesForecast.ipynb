{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priceData = pd.read_csv(\"./data/processed/pricesList.csv\")\n",
    "rainfallData = pd.read_csv(\"./data/processed/rainfallData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only one vegetable for the prediction\n",
    "priceData = priceData[priceData[\"Name\"] == \"Carrot_UPCVEG_1kg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureEngineering(data):\n",
    "    data2 = data.copy()\n",
    "    # iterate through the rainfallData and add the rainfall to the priceData\n",
    "    # for index, row in rainfallData.iterrows():\n",
    "    #     # match the year and month from the rainfall data to the pricedata\n",
    "    #     year = row['year']\n",
    "    #     month = row['month']\n",
    "    #     data2.loc[(data2['Year'] == year) & (data2['Month'] == month), 'anuradhapura'] = row['anuradhapura']\n",
    "    #     data2.loc[(data2['Year'] == year) & (data2['Month'] == month), 'jaffna'] = row['jaffna']\n",
    "    #     data2.loc[(data2['Year'] == year) & (data2['Month'] == month), 'nuwaraeliya'] = row['nuwaraeliya']\n",
    "\n",
    "    return data2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDate(data):\n",
    "    data2 = data.copy()\n",
    "    data2[\"Datetime\"] = pd.to_datetime(data2[['Year', 'Month']].assign(day=(data2[\"Week\"]-1)*7 +1))\n",
    "    data2 = data2.set_index('Datetime')\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(data):\n",
    "    data2 = data.copy()\n",
    "    data2 = data2.dropna()\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers\n",
    "from scipy.stats import gaussian_kde\n",
    "def remove_outliers_kde(df, column_name, threshold=0.05):\n",
    "    # Extract the values of the column\n",
    "    column_values = df[column_name].values\n",
    "    \n",
    "    # Fit the kernel density estimation\n",
    "    kde = gaussian_kde(column_values)\n",
    "    \n",
    "    # Evaluate the KDE for each data point\n",
    "    density = kde.evaluate(column_values)\n",
    "    \n",
    "    # Sort the data points by their density values\n",
    "    sorted_indices = np.argsort(density)\n",
    "    \n",
    "    # Calculate the threshold index based on the given threshold\n",
    "    threshold_index = int(len(sorted_indices) * threshold)\n",
    "    \n",
    "    # Get the indices of non-outliers\n",
    "    non_outlier_indices = sorted_indices[threshold_index:]\n",
    "    \n",
    "    # Filter out the non-outliers\n",
    "    df_cleaned = df.iloc[non_outlier_indices]\n",
    "    df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = featureEngineering(priceData);\n",
    "df = preprocessData(df);\n",
    "# df = remove_outliers_kde(df, 'Price')\n",
    "df = extractDate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Price\"].plot(style='.',figsize=(15, 5), title=\"Price Fluxuation of Carrot in Sri Lanka\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = \"2022-08-01\"\n",
    "train = df.loc[df.index < split_date]\n",
    "test = df.loc[df.index >= split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "train['Price'].plot(ax=ax, label=\"Train Set\", style=\".\")\n",
    "test['Price'].plot(ax=ax, label=\"Test Set\", style=\".\")\n",
    "ax.axvline(split_date, color=\"black\", ls=\"--\")\n",
    "ax.legend(\"Training set\", \"Test Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot week of data\n",
    "df[\"Price\"].loc[(df.index > \"2019-01-01\") & (df.index < \"2019-05-01\")].plot(style=\".\", figsize=(15, 5), title=\"Price Fluxuation of Carrot in Sri Lanka\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"Week\", \"Month\", \"Year\", \n",
    "            # \"anuradhapura\", \n",
    "            # \"jaffna\", \n",
    "            # \"nuwaraeliya\"\n",
    "            ]\n",
    "TARGET = \"Price\"\n",
    "\n",
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "reg = xgb.XGBRegressor(n_estimators=1741, learning_rate=0.01)\n",
    "reg.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], early_stopping_rounds=1741,verbose=50)\n",
    "# reg.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg = RandomForestRegressor(bootstrap=True, criterion='absolute_error',max_depth=None, max_leaf_nodes=None,n_estimators=10000, random_state=None, n_jobs=1, verbose=0)\n",
    "reg.fit(X_train, y_train)\n",
    "# reg.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'iterations': [1000, 5000, 10000, 20000],\n",
    "    'depth': [3, 5, 7],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'loss_function': ['RMSE']\n",
    "}\n",
    "reg = CatBoostRegressor()\n",
    "grid_search = GridSearchCV(estimator=reg, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "train_score = best_model.score(X_train, y_train)\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Train Score:\", train_score)\n",
    "print(\"Test Score:\", test_score)\n",
    "\n",
    "# reg = CatBoostRegressor(iterations=30000, depth=5, learning_rate=0.001, loss_function='RMSE')\n",
    "# reg.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100)\n",
    "# reg.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "model = Prophet()\n",
    "model.fit(train.reset_index().rename(columns={\"Datetime\": \"ds\", \"Price\": \"y\"}))\n",
    "forecast = model.predict(test.reset_index().rename(columns={\"Datetime\": \"ds\", \"Price\": \"y\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(figsize=(10, 5))\n",
    "fig = model.plot(forecast, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "ax.scatter(test.index, test[\"Price\"], color=\"r\", label=\"True Price\")\n",
    "fig = model.plot(forecast, ax=ax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast on test\n",
    "style = \".\"\n",
    "test2 = test.copy()\n",
    "test2[\"prediction\"] = reg.predict(X_test)\n",
    "df2 = df.merge(test2[[\"prediction\"]], how=\"left\", left_index=True, right_index=True)\n",
    "ax = df2[[\"Price\"]].plot(style=style, figsize=(15,5))\n",
    "df2[\"prediction\"].plot(style=style, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df2.loc[(df2.index > \"2022-08-01\") & (df2.index < \"2025-01-01\")][[\"Price\"]].plot(figsize=(15,5), style=style)\n",
    "df2.loc[(df2.index > \"2022-08-01\") & (df2.index < \"2025-01-01\")][\"prediction\"].plot(ax=ax, style=style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "stepwise_fit = auto_arima(df2[\"Price\"], trace=True, suppress_warnings=True)\n",
    "stepwise_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(train[\"Price\"], order=(2,1,2))\n",
    "model = model.fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = len(train)\n",
    "end = len(train) + len(test) - 1\n",
    "predictions = model.predict(start=start, end=end, typ=\"levels\").rename(\"ARIMA Predictions\")\n",
    "predictions.index = test.index\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.plot(legend=True)\n",
    "# test[\"Price\"].plot(legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
